## 5: 模型评估和训练

一个成熟合格的深度学习训练流程至少具备以下功能：
- 在训练集上进行训练，并在验证集上进行验证；
- 模型可以保存最优的权重，并读取权重；

实际上 [segmentation_models.pytorch](https://smp.readthedocs.io/en/latest/models.html#id9) 这个库已经给了我们绝大部分我们需要用到的模型，很多时候我们只需要在里面选择常用的一些网络模型
进行训练就好。目前我用的效果最好的不是paper最新的的DeepLabv3Plus，而是网络比较简单的PSPNet。所以这个具体区别还是得自己尝试。但是总体来说做完数据扩充之后选择相对更大更复杂一点的网络总体性能要好
不少。

### 5.1 构造验证集

在机器学习模型（特别是深度学习模型）的训练过程中，模型是非常容易过拟合的。深度学习模型在不断的训练过程中训练误差会逐渐降低，但测试误差的走势则不一定。

在模型的训练过程中，模型只能利用训练数据来进行训练，模型并不能接触到测试集上的样本。因此模型如果将训练集学的过好，模型就会记住训练样本的细节，导致模型在测试集的泛化效果较差，
这种现象称为过拟合（Overfitting）。与过拟合相对应的是欠拟合（Underfitting），即模型在训练集上的拟合效果较差。

![](https://github.com/datawhalechina/team-learning-cv/raw/master/AerialImageSegmentation/img/loss.png)

如图所示：随着模型复杂度和模型训练轮数的增加，CNN模型在训练集上的误差会降低，但在测试集上的误差会逐渐降低，然后逐渐升高，而我们为了追求的是模型在测试集上的精度越高越好。

导致模型过拟合的情况有很多种原因，其中最为常见的情况是模型复杂度（Model Complexity ）太高，导致模型学习到了训练数据的方方面面，学习到了一些细枝末节的规律。

解决上述问题最好的解决方法：构建一个与测试集尽可能分布一致的样本集（可称为验证集），在训练过程中不断验证模型在验证集上的精度，并以此控制模型的训练。

当然，不是所有的在测试集上的泛化效果较差的网络模型都发生了过拟合，而是有可能本身模型的复杂度就很低，导致在训练集上都没能很好的拟合数据，这个时候我们就需要增加模型的复杂度。

![](https://nvsyashwanth.github.io/machinelearningmaster/assets/images/bias_variance.jpg)

训练集误差和交叉验证集误差近似时：high bias/underfitting 交叉验证集误差远大于训练集误差时：high varience/overfitting。

![](http://www.ai-start.com/ml2014/images/25597f0f88208a7e74a3ca028e971852.png)
